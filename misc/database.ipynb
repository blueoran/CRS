{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import openai\n",
    "from openai.embeddings_utils import (\n",
    "    get_embedding,\n",
    "    distances_from_embeddings,\n",
    "    indices_of_nearest_neighbors_from_distances,\n",
    ")\n",
    "\n",
    "# constants\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../data/2022_movie.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "df['string'] = df.apply(\n",
    "                lambda x: \";\".join([f\"{k}:{v}\" for k, v in x.to_dict().items()]), axis=1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_cache_path = \"../data/recommendations_embeddings_cache.pkl\"\n",
    "\n",
    "# load the cache if it exists, and save a copy to disk\n",
    "try:\n",
    "    embedding_cache = pd.read_pickle(embedding_cache_path)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}\n",
    "with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "    pickle.dump(embedding_cache, embedding_cache_file)\n",
    "\n",
    "# define a function to retrieve embeddings from the cache if present, and otherwise request via the API\n",
    "def embedding_from_string(\n",
    "    string: str,\n",
    "    model: str = EMBEDDING_MODEL,\n",
    "    embedding_cache=embedding_cache\n",
    ") -> list:\n",
    "    \"\"\"Return embedding of given string, using a cache to avoid recomputing.\"\"\"\n",
    "    if (string, model) not in embedding_cache.keys():\n",
    "        embedding_cache[(string, model)] = get_embedding(string, model)\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(embedding_cache, embedding_cache_file)\n",
    "    return embedding_cache[(string, model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: Title:The Menu;rank:2.0;Year:(2022);certificate:R;Time:107 min;genre:Horror, Thriller;IMDB Score:7.2;Score:71 Metascore;Plot Summary:A young couple travels to a remote island to eat at an exclusive restaurant where the chef has prepared a lavish menu, with some shocking surprises.;director:Mark Mylod;actor1:Ralph Fiennes;actor2:Anya Taylor-Joy;actor3:Nicholas Hoult;actor4:Hong Chau;reviews:203,241;Unnamed: 15:nan\n",
      "\n",
      "Example embedding: [-0.0006663174135610461, -0.04418274760246277, -0.0012415433302521706, 0.006514728534966707, -0.005161851178854704, -0.0017864054534584284, -0.025856489315629005, -0.022685155272483826, -0.00462205009534955, -0.015802687034010887]...\n",
      "0.46652770042419434\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# as an example, take the first description from the dataset\n",
    "example_string = df[\"string\"].values[1]\n",
    "print(f\"\\nExample string: {example_string}\")\n",
    "start_time = time.time()\n",
    "# print the first 10 dimensions of the embedding\n",
    "example_embedding = embedding_from_string(example_string)\n",
    "print(f\"\\nExample embedding: {example_embedding[:10]}...\")\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_recommendations_from_strings(\n",
    "    strings: list[str],\n",
    "    index_of_source_string: int,\n",
    "    k_nearest_neighbors: int = 1,\n",
    "    model=EMBEDDING_MODEL,\n",
    ") -> list[int]:\n",
    "    \"\"\"Print out the k nearest neighbors of a given string.\"\"\"\n",
    "    # get embeddings for all strings\n",
    "    embeddings = [embedding_from_string(string, model=model) for string in strings]\n",
    "    # get the embedding of the source string\n",
    "    query_embedding = embeddings[index_of_source_string]\n",
    "    # get distances between the source embedding and other embeddings (function from embeddings_utils.py)\n",
    "    distances = distances_from_embeddings(query_embedding, embeddings, distance_metric=\"cosine\")\n",
    "    # get indices of nearest neighbors (function from embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)\n",
    "\n",
    "    # print out source string\n",
    "    query_string = strings[index_of_source_string]\n",
    "    print(f\"Source string: {query_string}\")\n",
    "    # print out its k nearest neighbors\n",
    "    k_counter = 0\n",
    "    for i in indices_of_nearest_neighbors:\n",
    "        # skip any strings that are identical matches to the starting string\n",
    "        if query_string == strings[i]:\n",
    "            continue\n",
    "        # stop after printing out k articles\n",
    "        if k_counter >= k_nearest_neighbors:\n",
    "            break\n",
    "        k_counter += 1\n",
    "\n",
    "        # print out the similar strings and their distances\n",
    "        print(\n",
    "            f\"\"\"\n",
    "        --- Recommendation #{k_counter} (nearest neighbor {k_counter} of {k_nearest_neighbors}) ---\n",
    "        String: {strings[i]}\n",
    "        Distance: {distances[i]:0.3f}\"\"\"\n",
    "        )\n",
    "\n",
    "    return indices_of_nearest_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
