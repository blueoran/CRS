{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "openai.api_key=apikey\n",
    "dialog_path=\"./data/Inspired/data/dialog_data/all.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle(x):\n",
    "    context=[]\n",
    "    for i in range(len(x)):\n",
    "        if x.iloc[i]['speaker']==\"RECOMMENDER\":\n",
    "            context.append(\"Assistant: \"+x.iloc[i]['text'])\n",
    "        else:\n",
    "            context.append(\"User: \"+x.iloc[i]['text'])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2302860/1254534323.py:1: DtypeWarning: Columns (1,3,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dialog=pd.read_csv(dialog_path,sep=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "dialog=pd.read_csv(dialog_path,sep=\"\\t\")\n",
    "dialog.groupby('dialog_id')[['speaker','text']].apply(handle).to_csv(\"./data/Inspired/data/dialog_data/all_context.tsv\",sep=\"\\t\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv(\"./data/Inspired/data/dialog_data/all_context.tsv\",sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=f\"\"\"\n",
    "I'm constructing a conversational recommendation system, and I want to design a test to evaluate its performance dealing with different situations. The following is a conversation between a user and a recommend assistant in the real world. Please read the conversation carefully and extract a general recommendation pattern of the requests from a user. Remember I am looking for various cases, so the more variation the pattern is, the better.\n",
    "\"\"\" \n",
    "completion=openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\":\"system\",\"content\":PROMPT},{\"role\":\"system\",\"content\":f\"dialog:\\n{a.iloc[5]}\"}],\n",
    "    temperature=1.0,\n",
    "    max_tokens=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided conversation, here is a general recommendation pattern for the user\\'s requests:\\n\\n1. User seeking recommendations for a specific category:\\n   - User explicitly asks for recommendations in a specific category, mentioning their preferences or requirements.\\n   - Assistant provides multiple recommendations based on the user\\'s preferences or requirements.\\n\\nExample: \\n- User: \"Can you recommend some good restaurants nearby?\"\\n- Assistant: \"Sure! What type of cuisine are you in the mood for?\"\\n\\n2. User seeking recommendations without specifying'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
